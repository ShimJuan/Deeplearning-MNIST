{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터셋 분류\n",
    "- 7000장의 숫자 이미지 \n",
    "- 사이즈 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 추가 데이터셋 로드 \n",
    "from keras.datasets import mnist\n",
    "# 필요한 라이브러리를 불러옵니다.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터로드 : keras.dataset 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n",
       " (array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 : 흰색의 부분. 흰색부분이 많기때문에 0이 많다\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_train[0],cmap ='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.데이터전처리\n",
    "    * training set / test set 분리 \n",
    "    * 이미지를 784*1 형태의 array 로 변환\n",
    "    * 정규화 : 0~1 사이의 값으로 바꾸기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype이 unuts 을 astype을 이용해 float으로 바꾸어준다.\n",
    "# 0~1사이의 값으로 변환한다/\n",
    "x_train = x_train.reshape(x_train.shape[0], 28*28).astype('float32')/255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28*28).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding\n",
    "y_train = np_utils.to_categorical(y_train,10)\n",
    "y_test = np_utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 생성\n",
    "    * ReLU, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 입력\n",
    "model.add(Dense(512,input_dim=784, activation='relu'))\n",
    "# 출력\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 컴파일\n",
    "     * loss : CCEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath='./model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss',patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.3038 - accuracy: 0.9146\n",
      "Epoch 00001: val_loss improved from inf to 0.14746, saving model to ./model/01-0.1475.hdf5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3027 - accuracy: 0.9150 - val_loss: 0.1475 - val_accuracy: 0.9568\n",
      "Epoch 2/30\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.1246 - accuracy: 0.9635\n",
      "Epoch 00002: val_loss improved from 0.14746 to 0.10198, saving model to ./model/02-0.1020.hdf5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1238 - accuracy: 0.9638 - val_loss: 0.1020 - val_accuracy: 0.9686\n",
      "Epoch 3/30\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9763\n",
      "Epoch 00003: val_loss improved from 0.10198 to 0.08908, saving model to ./model/03-0.0891.hdf5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0812 - accuracy: 0.9764 - val_loss: 0.0891 - val_accuracy: 0.9728\n",
      "Epoch 4/30\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9821\n",
      "Epoch 00004: val_loss improved from 0.08908 to 0.07819, saving model to ./model/04-0.0782.hdf5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0603 - accuracy: 0.9822 - val_loss: 0.0782 - val_accuracy: 0.9753\n",
      "Epoch 5/30\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9873\n",
      "Epoch 00005: val_loss improved from 0.07819 to 0.07342, saving model to ./model/05-0.0734.hdf5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.9874 - val_loss: 0.0734 - val_accuracy: 0.9774\n",
      "Epoch 6/30\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9901\n",
      "Epoch 00006: val_loss improved from 0.07342 to 0.06769, saving model to ./model/06-0.0677.hdf5\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9901 - val_loss: 0.0677 - val_accuracy: 0.9785\n",
      "Epoch 7/30\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9933\n",
      "Epoch 00007: val_loss improved from 0.06769 to 0.06513, saving model to ./model/07-0.0651.hdf5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0267 - accuracy: 0.9931 - val_loss: 0.0651 - val_accuracy: 0.9796\n",
      "Epoch 8/30\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9946\n",
      "Epoch 00008: val_loss improved from 0.06513 to 0.06330, saving model to ./model/08-0.0633.hdf5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.0633 - val_accuracy: 0.9803\n",
      "Epoch 9/30\n",
      "292/300 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9964\n",
      "Epoch 00009: val_loss did not improve from 0.06330\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.0634 - val_accuracy: 0.9791\n",
      "Epoch 10/30\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9976\n",
      "Epoch 00010: val_loss improved from 0.06330 to 0.06264, saving model to ./model/10-0.0626.hdf5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.0626 - val_accuracy: 0.9804\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9981\n",
      "Epoch 00011: val_loss did not improve from 0.06264\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0657 - val_accuracy: 0.9798\n",
      "Epoch 12/30\n",
      "294/300 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9989\n",
      "Epoch 00012: val_loss did not improve from 0.06264\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.0707 - val_accuracy: 0.9795\n",
      "Epoch 13/30\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9991\n",
      "Epoch 00013: val_loss improved from 0.06264 to 0.06009, saving model to ./model/13-0.0601.hdf5\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0601 - val_accuracy: 0.9821\n",
      "Epoch 14/30\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9996\n",
      "Epoch 00014: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0664 - val_accuracy: 0.9811\n",
      "Epoch 15/30\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9996\n",
      "Epoch 00015: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0707 - val_accuracy: 0.9813\n",
      "Epoch 16/30\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9997\n",
      "Epoch 00016: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0669 - val_accuracy: 0.9823\n",
      "Epoch 17/30\n",
      "293/300 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9997\n",
      "Epoch 00017: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0691 - val_accuracy: 0.9822\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 00018: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0742 - val_accuracy: 0.9815\n",
      "Epoch 19/30\n",
      "291/300 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9951\n",
      "Epoch 00019: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0883 - val_accuracy: 0.9779\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982\n",
      "Epoch 00020: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0700 - val_accuracy: 0.9826\n",
      "Epoch 21/30\n",
      "295/300 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 00021: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0678 - val_accuracy: 0.9822\n",
      "Epoch 22/30\n",
      "292/300 [============================>.] - ETA: 0s - loss: 7.6428e-04 - accuracy: 1.0000\n",
      "Epoch 00022: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 7.6210e-04 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9842\n",
      "Epoch 23/30\n",
      "295/300 [============================>.] - ETA: 0s - loss: 4.3747e-04 - accuracy: 1.0000\n",
      "Epoch 00023: val_loss did not improve from 0.06009\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 4.3453e-04 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9837\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=30,\n",
    "                   batch_size=200,callbacks=[early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
